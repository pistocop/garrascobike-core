{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4768bd33-ab5d-4544-b13b-f36f7618c4a6",
   "metadata": {},
   "source": [
    "# KNN recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad24a04-377b-43e9-bc8f-4ce38b33f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:2928976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e9molz</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9d9z1</td>\n",
       "      <td>Ibis Ripmo AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9as86</td>\n",
       "      <td>Airstream 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  thread_id   product_name\n",
       "0    e9molz            110\n",
       "1    e9d9z1  Ibis Ripmo AF\n",
       "2    e9as86    Airstream 2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('../../data/03_correlation_data/presence_dataset/20210331124802/presences.csv')\n",
    "df = df_raw.copy()\n",
    "print(f\"Dataset size:{df.memory_usage(index=True).sum()}\") # dtype category = 4_209_304 | no dtype category = 2_928_976 \n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed3167e-2eaf-40e3-97f7-be39fb6e91a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization product dimension: 40168\n",
      "Digits cleaning product dimension: 39727\n",
      "2-words product dimension: 10691\n",
      "Dataset len: 115237, columns:{'product_name', 'thread_id'}\n",
      "Unique threads:27577\n",
      "Unique products:10691\n",
      "Utility matrix - shape predicted:(27577, 10691)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Data cleaning\n",
    "###\n",
    "\n",
    "# String normalization\n",
    "df['product_name'] = df['product_name'].str.casefold()\n",
    "df['product_name'] = df['product_name'].str.strip()\n",
    "print(f\"Normalization product dimension: {len(df['product_name'].unique())}\")\n",
    "\n",
    "# Remove all products with all number on the name\n",
    "def has_numbers(inputString):\n",
    "    return all(char.isdigit() for char in inputString)\n",
    "df['name_with_digits'] = df['product_name'].apply(has_numbers)\n",
    "df = df[df[\"name_with_digits\"] == False]\n",
    "df = df.drop(\"name_with_digits\", 1)\n",
    "print(f\"Digits cleaning product dimension: {len(df['product_name'].unique())}\")\n",
    "\n",
    "# Remove all products with more than 2 words\n",
    "df = df[df['product_name'].str.split().str.len().lt(2)]\n",
    "print(f\"2-words product dimension: {len(df['product_name'].unique())}\")\n",
    "\n",
    "###\n",
    "# Metadata calculation\n",
    "###\n",
    "\n",
    "# Extract threads and products info\n",
    "threads_unique = df['thread_id'].unique()\n",
    "products_unique = df['product_name'].unique()\n",
    "util_mtx_dimension = (len(threads_unique), len(products_unique))\n",
    "\n",
    "print(f\"Dataset len: {len(df)}, columns:{set(df.columns)}\")\n",
    "print(f\"Unique threads:{len(threads_unique)}\")\n",
    "print(f\"Unique products:{len(products_unique)}\")\n",
    "print(f\"Utility matrix - shape predicted:{util_mtx_dimension}\")\n",
    "\n",
    "if util_mtx_dimension[1] > util_mtx_dimension[0]:\n",
    "    print(\"[INFO] There are more products than threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a98b3ea-8416-4d63-9458-0295eef89b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility matrix shape:(27577, 10691)[threads, products]\n",
      "Utility matrix structure:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[5., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 2., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from bidict import bidict\n",
    "\n",
    "# Build the indexer mapper\n",
    "thread2int = bidict({u:i for i, u in enumerate(df[\"thread_id\"].unique())})\n",
    "product2int = bidict({m:i for i, m in enumerate(df[\"product_name\"].unique())})\n",
    "\n",
    "# Map text to index\n",
    "threads_idx = [thread2int[u] for u in df[\"thread_id\"]]\n",
    "products_idx = [product2int[m] for m in df[\"product_name\"]]\n",
    "\n",
    "# Create matrix with 1 values [1,1,1,1,...[len(threads)]]\n",
    "data = np.ones(len(threads_idx), )\n",
    "\n",
    "# Create the utility matrix - sparse matrix [len(threads), len(products)]\n",
    "utility_matrix = csr_matrix((data, (threads_idx, products_idx)))\n",
    "assert utility_matrix.shape == util_mtx_dimension, f\"A_sparse have a wrong dimension, expected:{util_mtx_dimension}\"\n",
    "\n",
    "print(f\"Utility matrix shape:{utility_matrix.get_shape()}[threads, products]\")\n",
    "print(\"Utility matrix structure:\")\n",
    "utility_matrix.todense()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f3385-488e-4c5d-b217-d97a669ad881",
   "metadata": {},
   "source": [
    "#### Model\n",
    "> Scikit [doc](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6bebebe-5349-4e32-a24d-199e047820d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(metric='minkowski',\n",
    "                       p = 2,\n",
    "                       algorithm='auto', \n",
    "                       n_neighbors=5, \n",
    "                       n_jobs=-1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff9810c-1c7f-434f-b22e-31b3f4d8972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = utility_matrix.transpose() # shape required: (n_samples, n_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c66af908-b997-469a-85c7-aa6209e5486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(n_jobs=-1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d923f2a-179c-48eb-af9a-4f8f9dd0e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 'stoic' - id:48\n",
      "dis:0.0, idx:48, bike suggested:stoic\n",
      "dis:7.211102550927978, idx:1584, bike suggested:gf\n",
      "dis:7.3484692283495345, idx:706, bike suggested:superior\n",
      "dis:7.416198487095663, idx:1780, bike suggested:xp\n",
      "dis:7.681145747868608, idx:6977, bike suggested:respect\n",
      "dis:7.681145747868608, idx:6979, bike suggested:roo\n",
      "dis:7.681145747868608, idx:6974, bike suggested:skull120\n",
      "dis:7.681145747868608, idx:6975, bike suggested:jogon\n",
      "dis:7.681145747868608, idx:6972, bike suggested:52/36\n",
      "dis:7.681145747868608, idx:6986, bike suggested:superflash\n",
      "dis:7.681145747868608, idx:6989, bike suggested:xsmall\n"
     ]
    }
   ],
   "source": [
    "def get_bike_recommendation(bike_name):\n",
    "    neighbors = 10\n",
    "    bike_id = product2int.get(bike_name,None)\n",
    "    \n",
    "    if not bike_id:\n",
    "        print(f\"Bike {bike_name} not found\")\n",
    "        pass\n",
    "    print(f\"Searching '{bike_name}' - id:{bike_id}\")\n",
    "    \n",
    "    distances, indices = knn.kneighbors(train_matrix[bike_id], n_neighbors=neighbors+1)\n",
    "    distances, indices = distances.tolist().pop(), indices.tolist().pop()\n",
    "    \n",
    "    for dis, idx in zip(distances, indices):\n",
    "        bike_name = list(product2int.keys())[list(product2int.values()).index(idx)]\n",
    "        bike_name = product2int.inverse[idx]\n",
    "        print(f\"dis:{dis}, idx:{idx}, bike suggested:{bike_name}\")\n",
    "        \n",
    "get_bike_recommendation(\"stoic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
